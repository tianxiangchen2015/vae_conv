{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "from six.moves import cPickle\n",
    "import sys    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 400 epochs are set to run\n"
     ]
    }
   ],
   "source": [
    "# selecting parameters\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 64 \n",
    "\n",
    "# filter size    \n",
    "filter_rows = 1\n",
    "filter_cols = 2 \n",
    "\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "# subsampling size \n",
    "subsample_rows = 1 \n",
    "subsample_cols_a = 2    \n",
    "subsample_cols_b = 1\n",
    "\n",
    "# batch size \n",
    "batch_size = 50\n",
    "\n",
    "# dimension    \n",
    "latent_dim = 3\n",
    "intermediate_dim = 128\n",
    "\n",
    "# epsilon values \n",
    "mean=0.\n",
    "epsilon_std = 1.0      \n",
    "\n",
    "# dropout \n",
    "drop = 0\n",
    "\n",
    "# epoch, iteration sizes  \n",
    "nb_epoch = 1  \n",
    "\n",
    "# saving models: start & end\n",
    "nb_start = 0\n",
    "nb_end = 400       \n",
    "total_epochs = (nb_end-nb_start)*nb_epoch  \n",
    "print \"Total of %i epochs are set to run\" % total_epochs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directories creation compledted or if already exist - then checked\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "path_data = './X_110000.pkl.gz' \n",
    "path_1 = \"./fig\"\n",
    "path_2 = \"./imgs\"\n",
    "path_3 = \"./hist\"\n",
    "path_4 = \"./model\"\n",
    "if not os.path.exists(path_1):\n",
    "    os.mkdir(path_1, 0755);\n",
    "if not os.path.exists(path_2):\n",
    "    os.mkdir(path_2, 0755);\n",
    "if not os.path.exists(path_3):\n",
    "    os.mkdir(path_3, 0755);\n",
    "if not os.path.exists(path_4):\n",
    "    os.mkdir(path_4, 0755);   \n",
    "print \"directories creation compledted or if already exist - then checked\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with gzip.open(path_data, 'rb') as f3:    \n",
    "    (x_train_raw, y_train_raw), (x_test_raw,y_test_raw), (x_pred_raw,y_pred_raw) = cPickle.load(f3)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# normalizing input image matrix \n",
    "a = np.amax(x_train_raw)\n",
    "b = np.amax(x_test_raw)\n",
    "c = np.amax(x_pred_raw)\n",
    "x_train = x_train_raw.astype('float32') / a\n",
    "x_test = x_test_raw.astype('float32') / b\n",
    "x_pred = x_pred_raw.astype('float32') / c\n",
    "print x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 784\n"
     ]
    }
   ],
   "source": [
    "imag_rows = x_train_raw.shape[0]/len(x_train_raw)\n",
    "imag_cols = x_train_raw.shape[1]\n",
    "imag_chns = 1\n",
    "print imag_rows, imag_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neon.layers.layer import Layer, interpret_in_shape\n",
    "class Lambda(Layer):\n",
    "    '''\n",
    "    Take the input from previous layer and calculate the latent variable\n",
    "    '''\n",
    "\n",
    "    # constructor and initialize buffers\n",
    "    def __init__(self, nout, name=None):\n",
    "        super(Lambda, self).__init__(name)\n",
    "        self.nout = nout\n",
    "        \n",
    "        # required attributes\n",
    "        self.inputs = None  #..?\n",
    "        self.in_shape = None  # shape of the inputs to this layer\n",
    "        self.out_shape = None  # shape of the outputs from this layer\n",
    "\n",
    "    # configure the layer input and output shapes\n",
    "    def configure(self, in_obj):\n",
    "        super(Lambda, self).configure(in_obj)\n",
    "        (self.nin, self.nsteps) = interpret_in_shape(self.in_shape)\n",
    "        self.out_shape = (self.nout, self.nsteps)\n",
    "        return self\n",
    "        return self\n",
    "\n",
    "    # compute the fprop\n",
    "    def fprop(self, inputs, inference=False):\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        def sampling(data):\n",
    "            z_mean = z_log_var = data\n",
    "            epsilon = np.random.normal(0, 1.0, (data.shape))\n",
    "            return z_mean + np.exp(z_log_var)*epsilon\n",
    "        \n",
    "        for c in range(self.outputs.shape[1]):\n",
    "            self.outputs[:,c] = sampling(self.inputs[:,c])\n",
    "        return self.outputs\n",
    "\n",
    "    # backprop the gradients\n",
    "    def bprop(self, error):\n",
    "        if self.deltas is None:\n",
    "            self.deltas = error.reshape(self.in_shape, self.be.bsz)\n",
    "        self.deltas = error\n",
    "        return self.deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from neon.callbacks.callbacks import Callbacks\n",
    "from neon.data import ArrayIterator\n",
    "from neon.initializers import Gaussian\n",
    "from neon.layers import GeneralizedCost, Affine, Reshape\n",
    "from neon.models import Model\n",
    "from neon.optimizers import RMSProp\n",
    "from neon.transforms import Rectlin, Logistic, CrossEntropyBinary, Tanh\n",
    "from neon.transforms import Misclassification, Accuracy, Softmax\n",
    "from neon.layers import Conv, Affine, Pooling, Deconv, Dropout\n",
    "from neon.initializers import GlorotUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neon.backends import gen_backend\n",
    "be = gen_backend(backend='cpu', batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = ArrayIterator(X=x_train, lshape=(1, 28, 28))\n",
    "train_2 = ArrayIterator(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = GlorotUniform()\n",
    "activation = Rectlin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct Variance-Autoencoder layers.\n",
    "\n",
    "# layers = [Conv(fshape=(1, 1, 2), init=init, activation=activation, padding={\"pad_h\": 1}),\n",
    "#          Conv(fshape=(64, 1, 2), init=init, strides={\"str_w\":1, \"str_h\":2},\n",
    "#               activation=activation, padding={\"pad_h\":1}),\n",
    "#          Conv(fshape=(64, 3, 3), init=init, strides={\"str_w\":1, \"str_h\":1},\n",
    "#               activation=activation, padding={\"pad_h\":2, \"pad_w\":2}),\n",
    "#          Conv(fshape=(64, 3, 3), init=init, strides={\"str_w\":1, \"str_h\":1},\n",
    "#               activation=activation, padding={\"pad_h\":2, \"pad_w\":2}),\n",
    "#          Reshape(64*28*28),\n",
    "#           Affine(nout=128, init=init, activation=activation),\n",
    "#           Affine(nout=3, init=init, activation=activation),\n",
    "#          Lambda(),\n",
    "#           Affine(nout=128, init=init, activation=activation),\n",
    "#           Affine(nout=64*28*28, init=init, activation=activation),\n",
    "#           Reshape((64, 28, 28)),\n",
    "#           Deconv(fshape=(64, 3, 3), init=init, strides={\"str_w\":1, \"str_h\":1},\n",
    "#                 activation=activation, padding={\"pad_h\":2, \"pad_w\":2}),\n",
    "#           Deconv(fshape=(64, 3, 3), init=init, strides={\"str_w\":1, \"str_h\":1},\n",
    "#                 activation=activation, padding={\"pad_h\":2, \"pad_w\":2}),\n",
    "#           Deconv(fshape=(64, 1, 2), init=init, strides={\"str_w\":1, \"str_h\":2},\n",
    "#                 activation=activation, padding={\"pad_h\":1}),\n",
    "#           Deconv(fshape=(1, 1, 2), init=init, strides={\"str_w\":1, \"str_h\":2},\n",
    "#                 activation=Tanh(), padding={\"pad_h\":1})\n",
    "#          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test reshape and Lambda layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = [Affine(nout=128, init=init, activation=activation),\n",
    "          Reshape(reshape=(2,64)),\n",
    "          Reshape(reshape=128),\n",
    "          Affine(nout=3, init=init, activation=activation),\n",
    "          Lambda(nout=3),\n",
    "          Affine(nout=128, init=init, activation=activation),\n",
    "          Affine(nout=28*28, init=init, activation=activation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model(layers=layers)\n",
    "cost = GeneralizedCost(costfunc=CrossEntropyBinary())\n",
    "rms = RMSProp(learning_rate=0.001, epsilon=1e-08)\n",
    "callbacks = Callbacks(model, eval_set=train, eval_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_2, optimizer=rms, num_epochs=5, cost=cost, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
